{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3_3_Training_Customized_Mask_RCNN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMPOcfrdhO1v0xIMsQtND39"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ZcuabSbtbETw"},"source":["This tutorial will guide you to train Mask R-CNN to detect a new object.\r\n","\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"fji0UiHEeC8S"},"source":["---\r\n","## Gather and annotate training data\r\n","\r\n","The first step to training a new model is to create a training data set. For Mask R-CNN, we need images of scooters where each scooter has been traced out of the background. E.g.\r\n","\r\n","![scooter1.jpg](https://drive.google.com/uc?export=view&id=1ezxI6viuhMpTZS0_iPtXBdm5g2w29CPw)  \r\n","This means creating training data for an image segmentation model is a lot more time-consuming than creating training data for an image classification model. For image segmentation, we need to literally trace out the outline of each scooter. \r\n","\r\n","The easiest way to trace out each of our images is to use an annotation program specifically built for this purpose. There are many to choose from, e.g. makesense.io.  \r\n","\r\n","*\tThe VGG dataset provides an open source annotation tool that works on any operating system. \r\n","*\tThe COCO dataset also provides an annotation tool. \r\n","*\tIn addition, there are paid services like Labelbox that offer cloud-based annotation tools designed to help coordinate between multiple people annotating the same dataset. \r\n","\r\n","Whichever tool you use, you will want to spend a little time learning all the hotkeys for functions like drawing a new line, saving your drawings, and moving to the next image. Saving a few seconds on each image can really add up when you are tracing a lot of images. \r\n","\r\n","To collect the images of scooters, you can walked around your neighbourhood and took snapshots with your cell phone. To make sure the final model will work as well as possible, it’s important to take pictures of scooters in front of lots of different kinds of backgrounds. Since the model is learning how to tell the object apart from the background, the more kinds of backgrounds you train it on, the better it can learn. \r\n","\r\n","Tracing images is boring, but it’s important that you do as good a job as you can. If you trace the objects poorly, the final model won’t be very accurate. \r\n","\r\n","But we don’t necessarily need thousands of training images. To reduce the amount of training data we need, we can use the same transfer learning ideas we’ve used before! We can start with the pre-trained COCO model that we used in the last project and tweak it to detect scooters with only a small number of training images. Remember that Mask R-CNN is built using a complex configuration of CNNs, so everything we’ve learned about CNNs still applies. \r\n","\r\n","I’ve provided all the annotations I created so you don’t have to create any of your own to try out this project. But if you want to re-use this code to create your own model, you will have to annotate images yourself. \r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"TLrn_zh6zAQo"},"source":["---\n","### Mount to Google Drive\n","Mount to your Google Drive to access the images and model files."]},{"cell_type":"code","metadata":{"id":"5AK31II_h1Zm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610593373472,"user_tz":-480,"elapsed":829,"user":{"displayName":"Jimmy Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLSkpAlGxDPhWOsoJbyGqn037GeHQO859TaFZZ=s64","userId":"14200143294426892711"}},"outputId":"fd314dd2-0abb-48a8-cf18-2dfd4cd534f8"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","dataset_location = \"/content/drive/My Drive/Crafting/ADLCV/dataset/\""],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"I88CEUbfDhSS"},"source":["## Install Matterport Mask-RCNN in Google Colab"]},{"cell_type":"code","metadata":{"id":"JFaYtU8LUC49","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610593375678,"user_tz":-480,"elapsed":797,"user":{"displayName":"Jimmy Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLSkpAlGxDPhWOsoJbyGqn037GeHQO859TaFZZ=s64","userId":"14200143294426892711"}},"outputId":"7a7748f3-d9bc-4d71-886c-73a65e9410ac"},"source":["%tensorflow_version 1.x"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KtkuSGpBCZjV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610593381803,"user_tz":-480,"elapsed":3945,"user":{"displayName":"Jimmy Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLSkpAlGxDPhWOsoJbyGqn037GeHQO859TaFZZ=s64","userId":"14200143294426892711"}},"outputId":"b5e42715-662e-483f-c541-c16e2466d48c"},"source":["%cd /content\n","!git clone https://github.com/matterport/Mask_RCNN\n","%cd Mask_RCNN\n","!pip3 install -r requirements.txt\n","!python3 setup.py install"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content\n","fatal: destination path 'Mask_RCNN' already exists and is not an empty directory.\n","/content/Mask_RCNN\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.19.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.4.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (7.0.0)\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (0.29.21)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (3.2.2)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (0.16.2)\n","Requirement already satisfied: tensorflow>=1.3.0 in /tensorflow-1.15.2/python3.6 (from -r requirements.txt (line 7)) (1.15.2)\n","Requirement already satisfied: keras>=2.0.8 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (2.1.0)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (4.1.2.30)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (2.10.0)\n","Requirement already satisfied: imgaug in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 11)) (0.2.9)\n","Requirement already satisfied: IPython[all] in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 12)) (5.5.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.4.7)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2.5)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2.4.1)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r requirements.txt (line 6)) (1.1.1)\n","Requirement already satisfied: keras-applications>=1.0.8 in /tensorflow-1.15.2/python3.6 (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.0.8)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.1.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.15.0)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.2.2)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.12.1)\n","Requirement already satisfied: tensorflow-estimator==1.15.1 in /tensorflow-1.15.2/python3.6 (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.15.1)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.2.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.8.1)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.10.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.1.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.3.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.12.4)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.32.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.36.2)\n","Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /tensorflow-1.15.2/python3.6 (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.15.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.8->-r requirements.txt (line 8)) (3.13)\n","Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug->-r requirements.txt (line 11)) (1.7.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (0.7.5)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.4.2)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (2.6.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (51.1.1)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.3.3)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.8.0)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (1.0.18)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (0.8.1)\n","Requirement already satisfied: ipykernel; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.10.1)\n","Requirement already satisfied: nbconvert; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.6.1)\n","Requirement already satisfied: nbformat; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.0.8)\n","Requirement already satisfied: ipywidgets; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (7.6.3)\n","Requirement already satisfied: Sphinx>=1.3; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (1.8.5)\n","Requirement already satisfied: nose>=0.10.1; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (1.3.7)\n","Requirement already satisfied: qtconsole; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.0.1)\n","Requirement already satisfied: notebook; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.3.1)\n","Requirement already satisfied: ipyparallel; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (6.3.0)\n","Requirement already satisfied: requests; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (2.23.0)\n","Requirement already satisfied: testpath; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (0.4.4)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.3.3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.0.1)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->IPython[all]->-r requirements.txt (line 12)) (0.2.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->IPython[all]->-r requirements.txt (line 12)) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython[all]->-r requirements.txt (line 12)) (0.2.5)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (5.3.5)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (5.1.1)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.6.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.4.3)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (3.2.1)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (4.7.0)\n","Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.11.2)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.8.4)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.3)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.6.0)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.0.0)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (3.5.1)\n","Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.0.0)\n","Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.2.0)\n","Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.2.4)\n","Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.16)\n","Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.7.12)\n","Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.9.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (20.8)\n","Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.9.0)\n","Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (20.0.0)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.5.0)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.9.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (3.0.4)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.3.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.5.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.1.1)\n","Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.6/dist-packages (from sphinxcontrib-websupport->Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.1.4)\n","Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.6/dist-packages (from babel!=2.0,>=1.3->Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2018.9)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.4.0)\n","WARNING:root:Fail load requirements file, so using default ones.\n","running install\n","running bdist_egg\n","running egg_info\n","writing mask_rcnn.egg-info/PKG-INFO\n","writing dependency_links to mask_rcnn.egg-info/dependency_links.txt\n","writing top-level names to mask_rcnn.egg-info/top_level.txt\n","reading manifest template 'MANIFEST.in'\n","writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","running build_py\n","creating build/bdist.linux-x86_64/egg\n","creating build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/visualize.py -> build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/parallel_model.py -> build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/model.py -> build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/utils.py -> build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/__init__.py -> build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/config.py -> build/bdist.linux-x86_64/egg/mrcnn\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/visualize.py to visualize.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/parallel_model.py to parallel_model.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/model.py to model.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/utils.py to utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/config.py to config.cpython-36.pyc\n","creating build/bdist.linux-x86_64/egg/EGG-INFO\n","copying mask_rcnn.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying mask_rcnn.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying mask_rcnn.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying mask_rcnn.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","zip_safe flag not set; analyzing archive contents...\n","creating 'dist/mask_rcnn-2.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n","removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n","Processing mask_rcnn-2.1-py3.6.egg\n","Removing /usr/local/lib/python3.6/dist-packages/mask_rcnn-2.1-py3.6.egg\n","Copying mask_rcnn-2.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n","mask-rcnn 2.1 is already the active version in easy-install.pth\n","\n","Installed /usr/local/lib/python3.6/dist-packages/mask_rcnn-2.1-py3.6.egg\n","Processing dependencies for mask-rcnn==2.1\n","Finished processing dependencies for mask-rcnn==2.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"89qDTeoOwiAp","executionInfo":{"status":"ok","timestamp":1610593390852,"user_tz":-480,"elapsed":5053,"user":{"displayName":"Jimmy Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLSkpAlGxDPhWOsoJbyGqn037GeHQO859TaFZZ=s64","userId":"14200143294426892711"}},"outputId":"9a7a82ff-bc3a-47fb-a53e-9d48dee840c5"},"source":["!pip3 install xmltodict\r\n","!pip3 install keras==2.1.0"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: xmltodict in /usr/local/lib/python3.6/dist-packages (0.12.0)\n","Requirement already satisfied: keras==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.0) (3.13)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.0) (1.4.1)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.0) (1.19.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.0) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hyZW0FetHrbM","executionInfo":{"status":"ok","timestamp":1610593394957,"user_tz":-480,"elapsed":842,"user":{"displayName":"Jimmy Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLSkpAlGxDPhWOsoJbyGqn037GeHQO859TaFZZ=s64","userId":"14200143294426892711"}}},"source":["import os\n","\n","if os.getcwd() != \"/content/Mask_RCNN\":\n","  os.chdir(\"/content/Mask_RCNN\")"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LtBFtDkbE_U9"},"source":["## Imports libraries and define directories"]},{"cell_type":"code","metadata":{"id":"Kgz1u07FDqNV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610593399022,"user_tz":-480,"elapsed":2442,"user":{"displayName":"Jimmy Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLSkpAlGxDPhWOsoJbyGqn037GeHQO859TaFZZ=s64","userId":"14200143294426892711"}},"outputId":"373fa671-2eea-4398-8c9a-c6dc57f85945"},"source":["import os\n","import sys\n","import random\n","import math\n","import warnings\n","import numpy as np\n","import skimage.io\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","# Root directory of the project\n","ROOT_DIR = os.path.abspath(\"\")\n","\n","# Import Mask RCNN\n","sys.path.append(ROOT_DIR)  # To find local version of the library\n","from mrcnn import utils\n","import mrcnn.model as modellib\n","from mrcnn import visualize\n","from mrcnn.config import Config\n","sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))  # To find local version\n","import coco\n","\n","%matplotlib inline \n","\n","# Directory to save logs and trained model\n","MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n","\n","# Local path to trained weights file\n","COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n","# Download COCO trained weights from Releases if needed\n","if not os.path.exists(COCO_MODEL_PATH):\n","    utils.download_trained_weights(COCO_MODEL_PATH)\n","\n","# Directory of images to run detection on\n","#IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")\n","\n","# Directory of the training images\n","TRAINING_DATASET_PATH = os.path.join(dataset_location, \"MaskRCNN/scooter_training\")\n","\n","# Start training from the pre-trained COCO model. \n","WEIGHTS_TO_START_FROM = COCO_MODEL_PATH\n","#You can change this path if you want to pick up training from a prior\n","# checkpoint file in your ./logs folder.\n","# WEIGHTS_TO_START_FROM = os.path.join(MODEL_DIR, \"<h5_file_in_log>.h5\")"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"xubPQJs-FDT7"},"source":["## Configurations\n","\n","Instead of using the configurations of the COCO dataset, we need to manually define the configurations of out project. "]},{"cell_type":"code","metadata":{"id":"JP4z4LO0FD2G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610593404445,"user_tz":-480,"elapsed":847,"user":{"displayName":"Jimmy Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLSkpAlGxDPhWOsoJbyGqn037GeHQO859TaFZZ=s64","userId":"14200143294426892711"}},"outputId":"16219985-bf58-475a-973b-f2f68dec42c8"},"source":["class InferenceConfig(Config):\n","    NAME = \"custom_object\"\n","    IMAGES_PER_GPU = 1\n","    NUM_CLASSES = 1 + 1  # Background + your custom object\n","    STEPS_PER_EPOCH = 100\n","\n","    # Skip detections with < 90% confidence\n","    DETECTION_MIN_CONFIDENCE = 0.9\n","\n","config = InferenceConfig()\n","config.display()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["\n","Configurations:\n","BACKBONE                       resnet101\n","BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n","BATCH_SIZE                     1\n","BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n","COMPUTE_BACKBONE_SHAPE         None\n","DETECTION_MAX_INSTANCES        100\n","DETECTION_MIN_CONFIDENCE       0.9\n","DETECTION_NMS_THRESHOLD        0.3\n","FPN_CLASSIF_FC_LAYERS_SIZE     1024\n","GPU_COUNT                      1\n","GRADIENT_CLIP_NORM             5.0\n","IMAGES_PER_GPU                 1\n","IMAGE_CHANNEL_COUNT            3\n","IMAGE_MAX_DIM                  1024\n","IMAGE_META_SIZE                14\n","IMAGE_MIN_DIM                  800\n","IMAGE_MIN_SCALE                0\n","IMAGE_RESIZE_MODE              square\n","IMAGE_SHAPE                    [1024 1024    3]\n","LEARNING_MOMENTUM              0.9\n","LEARNING_RATE                  0.001\n","LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n","MASK_POOL_SIZE                 14\n","MASK_SHAPE                     [28, 28]\n","MAX_GT_INSTANCES               100\n","MEAN_PIXEL                     [123.7 116.8 103.9]\n","MINI_MASK_SHAPE                (56, 56)\n","NAME                           custom_object\n","NUM_CLASSES                    2\n","POOL_SIZE                      7\n","POST_NMS_ROIS_INFERENCE        1000\n","POST_NMS_ROIS_TRAINING         2000\n","PRE_NMS_LIMIT                  6000\n","ROI_POSITIVE_RATIO             0.33\n","RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n","RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n","RPN_ANCHOR_STRIDE              1\n","RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n","RPN_NMS_THRESHOLD              0.7\n","RPN_TRAIN_ANCHORS_PER_IMAGE    256\n","STEPS_PER_EPOCH                100\n","TOP_DOWN_PYRAMID_SIZE          256\n","TRAIN_BN                       False\n","TRAIN_ROIS_PER_IMAGE           200\n","USE_MINI_MASK                  True\n","USE_RPN_ROIS                   True\n","VALIDATION_STEPS               50\n","WEIGHT_DECAY                   0.0001\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ulJEWOZqFQfK","executionInfo":{"status":"ok","timestamp":1610593408879,"user_tz":-480,"elapsed":626,"user":{"displayName":"Jimmy Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLSkpAlGxDPhWOsoJbyGqn037GeHQO859TaFZZ=s64","userId":"14200143294426892711"}}},"source":["class_names = ['BG', 'scooter']"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5aZTtJ4snrRL"},"source":["---\r\n","## Parsing the Annotation Files.\r\n","\r\n","Now we have to deal with one of the annoying issues with building this kind of model. The problem is that every annotation program has its own preferred format for storing annotation data. The annotation tool that I used, RectLabel, creates data in the same format as the ***Pascal VOC dataset*** but the COCO dataset uses a different data format. There’s no common standard that every program or model uses. \r\n","\r\n","The Matterport Mask R-CNN implementation handles this by making you write a little bit of custom code to parse your annotation files. You need to subclass a Dataset class and re-implement the methods that read the annotation files, parse the contents, and generate masks from the polygons. \r\n","\r\n","Here’s the code to read RectLabel annotation files. First, we’ll define our custom dataset class and configure the folders we’ll pull our training data from. \r\n"]},{"cell_type":"code","metadata":{"id":"X_b9xi5wn91-","executionInfo":{"status":"ok","timestamp":1610593412024,"user_tz":-480,"elapsed":902,"user":{"displayName":"Jimmy Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLSkpAlGxDPhWOsoJbyGqn037GeHQO859TaFZZ=s64","userId":"14200143294426892711"}}},"source":["from pathlib import Path\r\n","import xmltodict\r\n","\r\n","class RectLabelDataset(utils.Dataset):\r\n","\r\n","    def load_training_images(self, dataset_dir, subset):\r\n","        dataset_dir = os.path.join(dataset_dir,subset)\r\n","        annotation_dir = os.path.join(dataset_dir, \"annotations\")\r\n","\r\n","        # Add classes. We have only one class to add since this model only detects one kind of object.\r\n","        self.add_class(\"custom_object\", 1, \"custom_object\")\r\n","        # Load each image by finding all the RectLabel annotation files and working backwards to the image.\r\n","        # This is a lot faster then having to load each image into memory.\r\n","        count = 0\r\n","        annotation_dir_path = Path(annotation_dir)\r\n","        for annotation_file in annotation_dir_path.glob(\"*.xml\"):\r\n","            print(f\"Parsing annotation: {annotation_file}\")\r\n","            xml_text = annotation_file.read_text()\r\n","            annotation = xmltodict.parse(xml_text)['annotation']\r\n","            objects = annotation['object']\r\n","            image_filename = annotation['filename']\r\n","            if not isinstance(objects, list):\r\n","                objects = [objects]\r\n","            # Add the image to the data set\r\n","            self.add_image(\r\n","                source=\"custom_object\",\r\n","                image_id=count,\r\n","                path=os.path.join(dataset_dir, image_filename),\r\n","                objects=objects,\r\n","                width=int(annotation[\"size\"]['width']),\r\n","                height=int(annotation[\"size\"]['height']),\r\n","            )\r\n","            count += 1\r\n","\r\n","    def load_mask(self, image_id):\r\n","        # We have to generate our own bitmap masks from the RectLabel polygons.\r\n","\r\n","        # Look up the current image id\r\n","        info = self.image_info[image_id]\r\n","        # Create a blank mask the same size as the image with as many depth channels as there are\r\n","        # annotations for this image.\r\n","        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"objects\"])], dtype=np.uint8)\r\n","        # Loop over each annotation for this image. Each annotation will get it's own channel in the mask image.\r\n","        for i, o in enumerate(info[\"objects\"]):\r\n","            # RectLabel uses Pascal VOC format which is kind of wacky.\r\n","            # We need to parse out the x/y coordinates of each point that make up the current polygon\r\n","            ys = []\r\n","            xs = []\r\n","            for label, number in o[\"polygon\"].items():\r\n","                number = int(number)\r\n","                if label.startswith(\"x\"):\r\n","                    xs.append(number)\r\n","                else:\r\n","                    ys.append(number)\r\n","\r\n","            # Draw the filled polygon on top of the mask image in the correct channel\r\n","            rr, cc = skimage.draw.polygon(ys, xs)\r\n","            mask[rr, cc, i] = 1\r\n","        # Return mask and array of class IDs of each instance. Since we have\r\n","        # one class ID only, we return an array of 1s\r\n","        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\r\n","\r\n","    def image_reference(self, image_id):\r\n","        # Get the path for the image\r\n","        info = self.image_info[image_id]\r\n","        return info[\"path\"]"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GDMavfw9FMyZ"},"source":["## Create Model and Load Trained Weights"]},{"cell_type":"code","metadata":{"id":"U5rFyxUtFMlZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610593435410,"user_tz":-480,"elapsed":17657,"user":{"displayName":"Jimmy Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLSkpAlGxDPhWOsoJbyGqn037GeHQO859TaFZZ=s64","userId":"14200143294426892711"}},"outputId":"a5e9f1dc-5a96-4d34-d53a-aad920e76b5d"},"source":["# Create model object in inference mode.\n","model = modellib.MaskRCNN(mode=\"training\", model_dir=MODEL_DIR, config=config)\n","\n","# Load weights trained on MS-COCO\n","# Load the weights we are going to start with\n","# Note: If you are picking up from a training checkpoint instead of the COCO weights, remove the excluded layers.\n","model.load_weights(WEIGHTS_TO_START_FROM, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])"],"execution_count":10,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:492: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:63: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3630: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3458: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1822: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1208: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1242: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:553: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n","\n","WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/utils.py:202: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:600: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:158: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:163: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:168: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:172: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:188: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1H3jLTRYrpZb"},"source":["---\r\n","## Run the training\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GYMt_lVDrxWf","executionInfo":{"status":"ok","timestamp":1610597667691,"user_tz":-480,"elapsed":4229108,"user":{"displayName":"Jimmy Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLSkpAlGxDPhWOsoJbyGqn037GeHQO859TaFZZ=s64","userId":"14200143294426892711"}},"outputId":"10149c33-1f37-47c8-f8bb-1894452f5543"},"source":["# Load the training data set\r\n","dataset_train = RectLabelDataset()\r\n","dataset_train.load_training_images(TRAINING_DATASET_PATH, \"training_set\")\r\n","dataset_train.prepare()\r\n","\r\n","# Load the validation data set\r\n","dataset_val = RectLabelDataset()\r\n","dataset_val.load_training_images(TRAINING_DATASET_PATH, \"validation_set\")\r\n","dataset_val.prepare()\r\n","\r\n","with warnings.catch_warnings():\r\n","    # Suppress annoying skimage warning due to code inside Mask R-CNN.\r\n","    # Not needed, but makes the output easier to read until Mask R-CNN is updated.\r\n","    warnings.simplefilter(\"ignore\")\r\n","\r\n","    # Re-train the model on a small data set. If you are training from \r\n","    # scratch with a huge data set,\r\n","    # you'd want to train longer and customize these settings.\r\n","    model.train(\r\n","        dataset_train,\r\n","        dataset_val,\r\n","        learning_rate=config.LEARNING_RATE,\r\n","        epochs=30,\r\n","        layers='heads'\r\n","    )\r\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180816_125220.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180816_125259.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180816_125453.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180816_133547.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180816_133629.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180816_133602.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180816_125443.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180816_133129.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180816_171347.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180816_171352.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180816_171533.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180816_171535.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180816_171539.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180816_171542.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180816_171544.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180816_172727.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180816_172734.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180816_172736.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180816_172744.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180816_172755.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180816_172746.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180817_085257.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180817_085259.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180817_085304.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180817_085311.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180817_085328.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180817_085335.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180817_090508.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180817_090512.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180817_090519.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180817_090759.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/training_set/annotations/20180816_172741.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/validation_set/annotations/20180816_125207.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/validation_set/annotations/20180816_133039.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/validation_set/annotations/20180816_133126.xml\n","Parsing annotation: /content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/validation_set/annotations/20180816_133618.xml\n","\n","Starting at epoch 0. LR=0.001\n","\n","Checkpoint Path: /content/Mask_RCNN/logs/custom_object20210114T0303/mask_rcnn_custom_object_{epoch:04d}.h5\n","Selecting layers to train\n","fpn_c5p5               (Conv2D)\n","fpn_c4p4               (Conv2D)\n","fpn_c3p3               (Conv2D)\n","fpn_c2p2               (Conv2D)\n","fpn_p5                 (Conv2D)\n","fpn_p2                 (Conv2D)\n","fpn_p3                 (Conv2D)\n","fpn_p4                 (Conv2D)\n","In model:  rpn_model\n","    rpn_conv_shared        (Conv2D)\n","    rpn_class_raw          (Conv2D)\n","    rpn_bbox_pred          (Conv2D)\n","mrcnn_mask_conv1       (TimeDistributed)\n","mrcnn_mask_bn1         (TimeDistributed)\n","mrcnn_mask_conv2       (TimeDistributed)\n","mrcnn_mask_bn2         (TimeDistributed)\n","mrcnn_class_conv1      (TimeDistributed)\n","mrcnn_class_bn1        (TimeDistributed)\n","mrcnn_mask_conv3       (TimeDistributed)\n","mrcnn_mask_bn3         (TimeDistributed)\n","mrcnn_class_conv2      (TimeDistributed)\n","mrcnn_class_bn2        (TimeDistributed)\n","mrcnn_mask_conv4       (TimeDistributed)\n","mrcnn_mask_bn4         (TimeDistributed)\n","mrcnn_bbox_fc          (TimeDistributed)\n","mrcnn_mask_deconv      (TimeDistributed)\n","mrcnn_class_logits     (TimeDistributed)\n","mrcnn_mask             (TimeDistributed)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:953: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:675: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:940: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:705: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:708: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n","\n","Epoch 1/30\n"," 99/100 [============================>.] - ETA: 1s - loss: 1.1687 - rpn_class_loss: 0.0193 - rpn_bbox_loss: 0.3250 - mrcnn_class_loss: 0.0635 - mrcnn_bbox_loss: 0.5232 - mrcnn_mask_loss: 0.2377WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:791: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n","\n","100/100 [==============================] - 259s 3s/step - loss: 1.1702 - rpn_class_loss: 0.0194 - rpn_bbox_loss: 0.3273 - mrcnn_class_loss: 0.0643 - mrcnn_bbox_loss: 0.5211 - mrcnn_mask_loss: 0.2382 - val_loss: 0.7437 - val_rpn_class_loss: 0.0150 - val_rpn_bbox_loss: 0.2119 - val_mrcnn_class_loss: 0.0305 - val_mrcnn_bbox_loss: 0.3683 - val_mrcnn_mask_loss: 0.1181\n","Epoch 2/30\n","100/100 [==============================] - 135s 1s/step - loss: 0.5799 - rpn_class_loss: 0.0102 - rpn_bbox_loss: 0.1515 - mrcnn_class_loss: 0.0362 - mrcnn_bbox_loss: 0.2447 - mrcnn_mask_loss: 0.1373 - val_loss: 0.8144 - val_rpn_class_loss: 0.0101 - val_rpn_bbox_loss: 0.2014 - val_mrcnn_class_loss: 0.0254 - val_mrcnn_bbox_loss: 0.4796 - val_mrcnn_mask_loss: 0.0979\n","Epoch 3/30\n","100/100 [==============================] - 131s 1s/step - loss: 0.5140 - rpn_class_loss: 0.0063 - rpn_bbox_loss: 0.1220 - mrcnn_class_loss: 0.0350 - mrcnn_bbox_loss: 0.2215 - mrcnn_mask_loss: 0.1292 - val_loss: 0.6577 - val_rpn_class_loss: 0.0062 - val_rpn_bbox_loss: 0.2291 - val_mrcnn_class_loss: 0.0245 - val_mrcnn_bbox_loss: 0.2944 - val_mrcnn_mask_loss: 0.1035\n","Epoch 4/30\n","100/100 [==============================] - 136s 1s/step - loss: 0.3777 - rpn_class_loss: 0.0051 - rpn_bbox_loss: 0.0927 - mrcnn_class_loss: 0.0282 - mrcnn_bbox_loss: 0.1349 - mrcnn_mask_loss: 0.1167 - val_loss: 0.5482 - val_rpn_class_loss: 0.0069 - val_rpn_bbox_loss: 0.1476 - val_mrcnn_class_loss: 0.0161 - val_mrcnn_bbox_loss: 0.2817 - val_mrcnn_mask_loss: 0.0959\n","Epoch 5/30\n","100/100 [==============================] - 133s 1s/step - loss: 0.3021 - rpn_class_loss: 0.0044 - rpn_bbox_loss: 0.0719 - mrcnn_class_loss: 0.0214 - mrcnn_bbox_loss: 0.0973 - mrcnn_mask_loss: 0.1072 - val_loss: 0.4707 - val_rpn_class_loss: 0.0054 - val_rpn_bbox_loss: 0.1869 - val_mrcnn_class_loss: 0.0168 - val_mrcnn_bbox_loss: 0.1707 - val_mrcnn_mask_loss: 0.0910\n","Epoch 6/30\n","100/100 [==============================] - 134s 1s/step - loss: 0.2611 - rpn_class_loss: 0.0034 - rpn_bbox_loss: 0.0593 - mrcnn_class_loss: 0.0188 - mrcnn_bbox_loss: 0.0824 - mrcnn_mask_loss: 0.0972 - val_loss: 0.4930 - val_rpn_class_loss: 0.0055 - val_rpn_bbox_loss: 0.1439 - val_mrcnn_class_loss: 0.0150 - val_mrcnn_bbox_loss: 0.2360 - val_mrcnn_mask_loss: 0.0926\n","Epoch 7/30\n","100/100 [==============================] - 133s 1s/step - loss: 0.2594 - rpn_class_loss: 0.0023 - rpn_bbox_loss: 0.0566 - mrcnn_class_loss: 0.0205 - mrcnn_bbox_loss: 0.0829 - mrcnn_mask_loss: 0.0970 - val_loss: 0.4857 - val_rpn_class_loss: 0.0047 - val_rpn_bbox_loss: 0.2014 - val_mrcnn_class_loss: 0.0153 - val_mrcnn_bbox_loss: 0.1778 - val_mrcnn_mask_loss: 0.0865\n","Epoch 8/30\n","100/100 [==============================] - 137s 1s/step - loss: 0.2286 - rpn_class_loss: 0.0027 - rpn_bbox_loss: 0.0543 - mrcnn_class_loss: 0.0172 - mrcnn_bbox_loss: 0.0654 - mrcnn_mask_loss: 0.0891 - val_loss: 0.5214 - val_rpn_class_loss: 0.0032 - val_rpn_bbox_loss: 0.2358 - val_mrcnn_class_loss: 0.0193 - val_mrcnn_bbox_loss: 0.1783 - val_mrcnn_mask_loss: 0.0849\n","Epoch 9/30\n","100/100 [==============================] - 137s 1s/step - loss: 0.2185 - rpn_class_loss: 0.0028 - rpn_bbox_loss: 0.0461 - mrcnn_class_loss: 0.0210 - mrcnn_bbox_loss: 0.0619 - mrcnn_mask_loss: 0.0866 - val_loss: 0.5147 - val_rpn_class_loss: 0.0043 - val_rpn_bbox_loss: 0.2053 - val_mrcnn_class_loss: 0.0170 - val_mrcnn_bbox_loss: 0.1989 - val_mrcnn_mask_loss: 0.0893\n","Epoch 10/30\n","100/100 [==============================] - 137s 1s/step - loss: 0.2033 - rpn_class_loss: 0.0027 - rpn_bbox_loss: 0.0527 - mrcnn_class_loss: 0.0159 - mrcnn_bbox_loss: 0.0472 - mrcnn_mask_loss: 0.0847 - val_loss: 0.4976 - val_rpn_class_loss: 0.0038 - val_rpn_bbox_loss: 0.1862 - val_mrcnn_class_loss: 0.0160 - val_mrcnn_bbox_loss: 0.2051 - val_mrcnn_mask_loss: 0.0866\n","Epoch 11/30\n","100/100 [==============================] - 136s 1s/step - loss: 0.1848 - rpn_class_loss: 0.0021 - rpn_bbox_loss: 0.0471 - mrcnn_class_loss: 0.0171 - mrcnn_bbox_loss: 0.0358 - mrcnn_mask_loss: 0.0827 - val_loss: 0.5367 - val_rpn_class_loss: 0.0044 - val_rpn_bbox_loss: 0.2329 - val_mrcnn_class_loss: 0.0080 - val_mrcnn_bbox_loss: 0.2023 - val_mrcnn_mask_loss: 0.0891\n","Epoch 12/30\n","100/100 [==============================] - 137s 1s/step - loss: 0.1686 - rpn_class_loss: 0.0022 - rpn_bbox_loss: 0.0334 - mrcnn_class_loss: 0.0145 - mrcnn_bbox_loss: 0.0410 - mrcnn_mask_loss: 0.0775 - val_loss: 0.4714 - val_rpn_class_loss: 0.0034 - val_rpn_bbox_loss: 0.1937 - val_mrcnn_class_loss: 0.0060 - val_mrcnn_bbox_loss: 0.1766 - val_mrcnn_mask_loss: 0.0917\n","Epoch 13/30\n","100/100 [==============================] - 135s 1s/step - loss: 0.1629 - rpn_class_loss: 0.0023 - rpn_bbox_loss: 0.0342 - mrcnn_class_loss: 0.0124 - mrcnn_bbox_loss: 0.0366 - mrcnn_mask_loss: 0.0774 - val_loss: 0.5250 - val_rpn_class_loss: 0.0036 - val_rpn_bbox_loss: 0.2398 - val_mrcnn_class_loss: 0.0090 - val_mrcnn_bbox_loss: 0.1755 - val_mrcnn_mask_loss: 0.0972\n","Epoch 14/30\n","100/100 [==============================] - 138s 1s/step - loss: 0.1490 - rpn_class_loss: 0.0020 - rpn_bbox_loss: 0.0286 - mrcnn_class_loss: 0.0134 - mrcnn_bbox_loss: 0.0309 - mrcnn_mask_loss: 0.0741 - val_loss: 0.5367 - val_rpn_class_loss: 0.0026 - val_rpn_bbox_loss: 0.2329 - val_mrcnn_class_loss: 0.0094 - val_mrcnn_bbox_loss: 0.2041 - val_mrcnn_mask_loss: 0.0876\n","Epoch 15/30\n","100/100 [==============================] - 138s 1s/step - loss: 0.1419 - rpn_class_loss: 0.0020 - rpn_bbox_loss: 0.0313 - mrcnn_class_loss: 0.0101 - mrcnn_bbox_loss: 0.0263 - mrcnn_mask_loss: 0.0722 - val_loss: 0.5087 - val_rpn_class_loss: 0.0019 - val_rpn_bbox_loss: 0.2069 - val_mrcnn_class_loss: 0.0080 - val_mrcnn_bbox_loss: 0.2008 - val_mrcnn_mask_loss: 0.0912\n","Epoch 16/30\n","100/100 [==============================] - 135s 1s/step - loss: 0.1421 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.0322 - mrcnn_class_loss: 0.0126 - mrcnn_bbox_loss: 0.0248 - mrcnn_mask_loss: 0.0710 - val_loss: 0.4769 - val_rpn_class_loss: 0.0027 - val_rpn_bbox_loss: 0.2026 - val_mrcnn_class_loss: 0.0095 - val_mrcnn_bbox_loss: 0.1642 - val_mrcnn_mask_loss: 0.0980\n","Epoch 17/30\n","100/100 [==============================] - 135s 1s/step - loss: 0.1294 - rpn_class_loss: 0.0015 - rpn_bbox_loss: 0.0228 - mrcnn_class_loss: 0.0101 - mrcnn_bbox_loss: 0.0269 - mrcnn_mask_loss: 0.0681 - val_loss: 0.5023 - val_rpn_class_loss: 0.0024 - val_rpn_bbox_loss: 0.2173 - val_mrcnn_class_loss: 0.0094 - val_mrcnn_bbox_loss: 0.1842 - val_mrcnn_mask_loss: 0.0890\n","Epoch 18/30\n","100/100 [==============================] - 135s 1s/step - loss: 0.1157 - rpn_class_loss: 0.0015 - rpn_bbox_loss: 0.0153 - mrcnn_class_loss: 0.0107 - mrcnn_bbox_loss: 0.0182 - mrcnn_mask_loss: 0.0701 - val_loss: 0.5063 - val_rpn_class_loss: 0.0024 - val_rpn_bbox_loss: 0.2165 - val_mrcnn_class_loss: 0.0085 - val_mrcnn_bbox_loss: 0.1859 - val_mrcnn_mask_loss: 0.0931\n","Epoch 19/30\n","100/100 [==============================] - 137s 1s/step - loss: 0.1160 - rpn_class_loss: 0.0013 - rpn_bbox_loss: 0.0155 - mrcnn_class_loss: 0.0109 - mrcnn_bbox_loss: 0.0197 - mrcnn_mask_loss: 0.0686 - val_loss: 0.5201 - val_rpn_class_loss: 0.0029 - val_rpn_bbox_loss: 0.2153 - val_mrcnn_class_loss: 0.0136 - val_mrcnn_bbox_loss: 0.1956 - val_mrcnn_mask_loss: 0.0927\n","Epoch 20/30\n","100/100 [==============================] - 137s 1s/step - loss: 0.1194 - rpn_class_loss: 0.0012 - rpn_bbox_loss: 0.0196 - mrcnn_class_loss: 0.0102 - mrcnn_bbox_loss: 0.0248 - mrcnn_mask_loss: 0.0637 - val_loss: 0.5668 - val_rpn_class_loss: 0.0026 - val_rpn_bbox_loss: 0.2496 - val_mrcnn_class_loss: 0.0159 - val_mrcnn_bbox_loss: 0.2096 - val_mrcnn_mask_loss: 0.0891\n","Epoch 21/30\n","100/100 [==============================] - 139s 1s/step - loss: 0.1227 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.0248 - mrcnn_class_loss: 0.0116 - mrcnn_bbox_loss: 0.0209 - mrcnn_mask_loss: 0.0639 - val_loss: 0.6130 - val_rpn_class_loss: 0.0028 - val_rpn_bbox_loss: 0.2875 - val_mrcnn_class_loss: 0.0098 - val_mrcnn_bbox_loss: 0.2114 - val_mrcnn_mask_loss: 0.1015\n","Epoch 22/30\n","100/100 [==============================] - 139s 1s/step - loss: 0.1134 - rpn_class_loss: 0.0012 - rpn_bbox_loss: 0.0177 - mrcnn_class_loss: 0.0109 - mrcnn_bbox_loss: 0.0190 - mrcnn_mask_loss: 0.0644 - val_loss: 0.4800 - val_rpn_class_loss: 0.0026 - val_rpn_bbox_loss: 0.2250 - val_mrcnn_class_loss: 0.0112 - val_mrcnn_bbox_loss: 0.1475 - val_mrcnn_mask_loss: 0.0939\n","Epoch 23/30\n","100/100 [==============================] - 136s 1s/step - loss: 0.1089 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.0148 - mrcnn_class_loss: 0.0098 - mrcnn_bbox_loss: 0.0172 - mrcnn_mask_loss: 0.0656 - val_loss: 0.4855 - val_rpn_class_loss: 0.0028 - val_rpn_bbox_loss: 0.2051 - val_mrcnn_class_loss: 0.0089 - val_mrcnn_bbox_loss: 0.1781 - val_mrcnn_mask_loss: 0.0906\n","Epoch 24/30\n","100/100 [==============================] - 137s 1s/step - loss: 0.1177 - rpn_class_loss: 0.0012 - rpn_bbox_loss: 0.0195 - mrcnn_class_loss: 0.0113 - mrcnn_bbox_loss: 0.0231 - mrcnn_mask_loss: 0.0627 - val_loss: 0.5261 - val_rpn_class_loss: 0.0021 - val_rpn_bbox_loss: 0.2089 - val_mrcnn_class_loss: 0.0086 - val_mrcnn_bbox_loss: 0.2108 - val_mrcnn_mask_loss: 0.0957\n","Epoch 25/30\n","100/100 [==============================] - 138s 1s/step - loss: 0.1031 - rpn_class_loss: 0.0012 - rpn_bbox_loss: 0.0178 - mrcnn_class_loss: 0.0095 - mrcnn_bbox_loss: 0.0137 - mrcnn_mask_loss: 0.0609 - val_loss: 0.4787 - val_rpn_class_loss: 0.0019 - val_rpn_bbox_loss: 0.1709 - val_mrcnn_class_loss: 0.0243 - val_mrcnn_bbox_loss: 0.1842 - val_mrcnn_mask_loss: 0.0975\n","Epoch 26/30\n","100/100 [==============================] - 137s 1s/step - loss: 0.1022 - rpn_class_loss: 0.0012 - rpn_bbox_loss: 0.0135 - mrcnn_class_loss: 0.0105 - mrcnn_bbox_loss: 0.0115 - mrcnn_mask_loss: 0.0656 - val_loss: 0.4953 - val_rpn_class_loss: 0.0021 - val_rpn_bbox_loss: 0.2087 - val_mrcnn_class_loss: 0.0122 - val_mrcnn_bbox_loss: 0.1770 - val_mrcnn_mask_loss: 0.0953\n","Epoch 27/30\n","100/100 [==============================] - 137s 1s/step - loss: 0.0880 - rpn_class_loss: 9.8342e-04 - rpn_bbox_loss: 0.0083 - mrcnn_class_loss: 0.0098 - mrcnn_bbox_loss: 0.0091 - mrcnn_mask_loss: 0.0597 - val_loss: 0.5121 - val_rpn_class_loss: 0.0022 - val_rpn_bbox_loss: 0.2280 - val_mrcnn_class_loss: 0.0184 - val_mrcnn_bbox_loss: 0.1730 - val_mrcnn_mask_loss: 0.0905\n","Epoch 28/30\n","100/100 [==============================] - 137s 1s/step - loss: 0.0867 - rpn_class_loss: 9.8486e-04 - rpn_bbox_loss: 0.0082 - mrcnn_class_loss: 0.0083 - mrcnn_bbox_loss: 0.0113 - mrcnn_mask_loss: 0.0580 - val_loss: 0.5153 - val_rpn_class_loss: 0.0015 - val_rpn_bbox_loss: 0.2323 - val_mrcnn_class_loss: 0.0184 - val_mrcnn_bbox_loss: 0.1677 - val_mrcnn_mask_loss: 0.0954\n","Epoch 29/30\n","100/100 [==============================] - 137s 1s/step - loss: 0.0878 - rpn_class_loss: 0.0010 - rpn_bbox_loss: 0.0095 - mrcnn_class_loss: 0.0082 - mrcnn_bbox_loss: 0.0117 - mrcnn_mask_loss: 0.0574 - val_loss: 0.5366 - val_rpn_class_loss: 0.0016 - val_rpn_bbox_loss: 0.2222 - val_mrcnn_class_loss: 0.0096 - val_mrcnn_bbox_loss: 0.2095 - val_mrcnn_mask_loss: 0.0938\n","Epoch 30/30\n","100/100 [==============================] - 134s 1s/step - loss: 0.0787 - rpn_class_loss: 8.4214e-04 - rpn_bbox_loss: 0.0066 - mrcnn_class_loss: 0.0071 - mrcnn_bbox_loss: 0.0082 - mrcnn_mask_loss: 0.0559 - val_loss: 0.5383 - val_rpn_class_loss: 0.0018 - val_rpn_bbox_loss: 0.2230 - val_mrcnn_class_loss: 0.0139 - val_mrcnn_bbox_loss: 0.1975 - val_mrcnn_mask_loss: 0.1021\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cfQ4K03AsY-A"},"source":["---\r\n","## Copy the trained model to Google Drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"FlI1EGKBseKI","executionInfo":{"status":"ok","timestamp":1610597736229,"user_tz":-480,"elapsed":1623,"user":{"displayName":"Jimmy Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLSkpAlGxDPhWOsoJbyGqn037GeHQO859TaFZZ=s64","userId":"14200143294426892711"}},"outputId":"5bb7a2b2-7a63-4952-8f01-ab7f07c930f6"},"source":["import shutil\r\n","# Use the Files explorer of Google Colaboratory \r\n","# to obtain the path of the coustomized h5 file.\r\n","H5_PATH = \"<Paste the path here>\"\r\n","shutil.copy(H5_PATH, \r\n","            os.path.join(TRAINING_DATASET_PATH,'customized_model.h5'))"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/Crafting/ADLCV/dataset/MaskRCNN/scooter_training/customized_model.h5'"]},"metadata":{"tags":[]},"execution_count":12}]}]}